# ZERO-SHOT-VIDEO-GENERATION

## Introduction
The Zero-Shot Video Generation ML Project is an innovative solution for transforming text into dynamic video content. This README guides you through setting up and running the project on your local machine.

## Prerequisites
- Python 3.8+

## Installation

### Step 1: Clone the Repository
```bash
git clone https://github.com/Amey-Thakur/ZERO-SHOT-VIDEO-GENERATIO
# Or download and extract the zip file
```

### Step 2: Install Dependencies
Navigate to the project directory and run:
```bash
pip install -r requirements.txt
```
This installs necessary libraries like `torch`, `numpy`, `opencv`, `gradio`, and `moviepy`.

### Step 3: Starting the Project
In the project directory, run:
```bash
python app.py
```
This starts the server and initializes the Text2Video model.

## Usage

### Step 4: Accessing the Local Server
Copy the localhost link (typically `http://127.0.0.1:7860`) from the terminal into your web browser.

### Step 5: Interacting with the Text2Video Model
Enter the desired text into the model's interface on the server page to start video generation.

### Step 6: Generating Video
Trigger the model to process the text and generate the video.

### Step 7: Viewing Results
Review the generated video displayed on the webpage directly in the browser.

## Conclusion
Enjoy transforming text into videos with ease and efficiency! For further details, refer to the project documentation.
